{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook reproducing some of the examples from chapter 3 of Hastie, Tibshirani, Friedman, *The Elements of Statistical Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as spl\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlalgos.supervised_learning.linear_regression import (\n",
    "    DummyRegression,\n",
    "    LinearRegression,\n",
    "    LassoRegression,\n",
    "    PrincipalComponentsRegression,\n",
    "    RidgeRegression,\n",
    "    PartialLeastSquaresRegression\n",
    ")\n",
    "from mlalgos.utils.data_utils import StandardScaler, cross_validation_split\n",
    "from mlalgos.utils.error_funcs import mean_squared_error\n",
    "from mlalgos.utils.plotting import plot_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prostate_data = '~/datasets/prostate.txt'\n",
    "df = pd.read_csv(prostate_data, sep='\\t', usecols=[1,2,3,4,5,6,7,8,9,10])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']\n"
     ]
    }
   ],
   "source": [
    "target = 'lpsa'\n",
    "features = list(df)\n",
    "features.remove('lpsa')\n",
    "features.remove('train')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train flag to split\n",
    "train = df.train == 'T'\n",
    "X, y = df[features].values, df[target].values\n",
    "X_train, y_train = X[train], y[train]\n",
    "X_test, y_test = X[~train], y[~train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000000000002, 0.30023198690216274, 0.28632426557510204, 0.06316772022296163, 0.592949130529482, 0.6920430753226345, 0.4264140724486782, 0.48316135710366304], [0.30023198690216274, 0.9999999999999999, 0.31672346842086035, 0.437041536580065, 0.1810544782843504, 0.15682859478541616, 0.023558207288831432, 0.0741663208573534], [0.28632426557510204, 0.31672346842086035, 0.9999999999999999, 0.28734644573788043, 0.12890226303142774, 0.172951397595152, 0.3659151225132289, 0.2758057291244312], [0.06316772022296163, 0.437041536580065, 0.28734644573788043, 0.9999999999999998, -0.13914679926810444, -0.08853455936907369, 0.032992152046930436, -0.030403819438876666], [0.592949130529482, 0.1810544782843504, 0.12890226303142774, -0.13914679926810444, 1.0, 0.6712402103032987, 0.3068753723785833, 0.48135774093302786], [0.6920430753226345, 0.15682859478541616, 0.172951397595152, -0.08853455936907369, 0.6712402103032987, 1.0000000000000002, 0.4764368357350071, 0.6625333515651151], [0.4264140724486782, 0.023558207288831432, 0.3659151225132289, 0.032992152046930436, 0.3068753723785833, 0.4764368357350071, 0.9999999999999999, 0.7570564964001196], [0.48316135710366304, 0.0741663208573534, 0.2758057291244312, -0.030403819438876666, 0.48135774093302786, 0.6625333515651151, 0.7570564964001196, 1.0000000000000002]]\n"
     ]
    }
   ],
   "source": [
    "# correlation matrix\n",
    "corr = []\n",
    "for feature1 in features:\n",
    "    corr_list = []\n",
    "    x1 = df[train][feature1].values\n",
    "    mean1 = np.mean(x1)\n",
    "    std1 = np.std(x1)\n",
    "    for feature2 in features:\n",
    "        x2 = df[train][feature2].values\n",
    "        mean2 = np.mean(x2)\n",
    "        std2 = np.std(x2)\n",
    "        c = np.mean((x1-mean1)*(x2-mean2))/(std1*std2)\n",
    "        corr_list.append(c)\n",
    "    corr.append(corr_list)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "\n",
       "            pgg45  \n",
       "lcavol   0.483161  \n",
       "lweight  0.074166  \n",
       "age      0.275806  \n",
       "lbph    -0.030404  \n",
       "svi      0.481358  \n",
       "lcp      0.662533  \n",
       "gleason  0.757056  \n",
       "pgg45    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation matrix using pandas (tab. 3.1)\n",
    "df[train][features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base error rate:  1.0567332280603818\n"
     ]
    }
   ],
   "source": [
    "# base error rate by simply predicting the mean\n",
    "dummy_model = DummyRegression()\n",
    "dummy_model.fit(X_train, y_train)\n",
    "base_error_rate = mean_squared_error(y_test, dummy_model.predict(X_test))\n",
    "print('Base error rate: ', base_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise for unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute linear regression and some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept \t 2.4523450850746276\n",
      "lcavol \t 0.7110405922561779\n",
      "lweight \t 0.2904502919864316\n",
      "age \t -0.14148182348942576\n",
      "lbph \t 0.210419510184796\n",
      "svi \t 0.3073002529718587\n",
      "lcp \t -0.28684074913663926\n",
      "gleason \t -0.020756862036926726\n",
      "pgg45 \t 0.27526842547776587\n"
     ]
    }
   ],
   "source": [
    "# The difference in parameters compared to Tab 3.2 in ESL is due to standardising the data only on the training data,\n",
    "# rather than the whole dataset, as done in the book. This propagates to later results\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "beta_names = ['Intercept'] + features\n",
    "for i in range(len(beta_names)):\n",
    "    print(beta_names[i], '\\t', linear_model.beta_hat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08701959 0.13250132 0.10558798 0.10135462 0.1023518  0.12445059\n",
      " 0.15364444 0.14151003 0.1583969 ]\n"
     ]
    }
   ],
   "source": [
    "# standard errors\n",
    "X_tmp = np.insert(X_train, 0, 1, axis=1)\n",
    "vary = np.sum((y_train - linear_model.predict(X_train))**2)/(len(y_train)-len(features)-1)\n",
    "errs = np.sqrt(np.diagonal(spl.inv(X_tmp.T @ X_tmp)) * vary)\n",
    "print(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.18152744197761, 5.3662904561505105, 2.750789389869384, -1.3959089818189574, 2.0558456259309086, 2.4692551777938414, -1.8669126353948038, -0.14668120644371685, 1.737839719569908]\n"
     ]
    }
   ],
   "source": [
    "# z score\n",
    "z = []\n",
    "for i in range(len(beta_names)):\n",
    "    z.append(linear_model.beta_hat[i]/errs[i])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term            Coeff    Std. Err      Z Score\n",
      "-----------------------------------------------\n",
      " Intercept      2.45     0.09          28.18\n",
      "    lcavol      0.71     0.13           5.37\n",
      "   lweight      0.29     0.11           2.75\n",
      "       age     -0.14     0.10          -1.40\n",
      "      lbph      0.21     0.10           2.06\n",
      "       svi      0.31     0.12           2.47\n",
      "       lcp     -0.29     0.15          -1.87\n",
      "   gleason     -0.02     0.14          -0.15\n",
      "     pgg45      0.28     0.16           1.74\n"
     ]
    }
   ],
   "source": [
    "result = zip(beta_names, linear_model.beta_hat, errs, z)\n",
    "print('Term            Coeff    Std. Err      Z Score')\n",
    "print('-----------------------------------------------')\n",
    "for term, coefficient, std_err, z_score in result:\n",
    "    print(f'{term:>10}{coefficient:>10.2f}{std_err:>9.2f}{z_score:>15.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error     0.52\n",
      "Base error           1.06\n"
     ]
    }
   ],
   "source": [
    "# prediction error\n",
    "pred_err = mean_squared_error(linear_model.predict(X_test), y_test)\n",
    "print(f'{\"Prediction error\":20}{pred_err:5.2f}')\n",
    "print(f'{\"Base error\":20}{base_error_rate:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping:  ['age' 'lcp' 'gleason' 'pgg45']\n",
      "F = 1.67\n",
      "p-value = 0.17\n"
     ]
    }
   ],
   "source": [
    "# F score from dropping age, lcp, gleason, pgg45 (the features with lowest absolute z-score)\n",
    "N = len(y_train)\n",
    "RSS1 = mean_squared_error(linear_model.predict(X_train), y_train) * N\n",
    "betas0 = linear_model.beta_hat.copy()\n",
    "indxs = list(np.where(np.array(np.abs(z)) < 2)[0])\n",
    "print('Dropping: ', np.array(beta_names)[indxs])\n",
    "features0 = features.copy()\n",
    "for i in indxs:\n",
    "    features0.remove(beta_names[i])\n",
    "X0_train = df[features0].values[train]\n",
    "linear_model0 = LinearRegression()\n",
    "linear_model0.fit(X0_train, y_train)\n",
    "RSS0 = mean_squared_error(linear_model0.predict(X0_train), y_train) * N\n",
    "p1 = 9\n",
    "p0 = 5\n",
    "F = ((RSS0-RSS1)/(p1-p0))/(RSS1/(N-p1))\n",
    "Fdist = sps.f(p1-p0,N-p1-1)\n",
    "p_val = Fdist.sf(F)\n",
    "print(f'{\"F = \"}{F:.2f}')\n",
    "print(f'{\"p-value = \"}{p_val:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we cannot reject the null hypothesis (of setting the four features with lowest absolute z-score to zero) as the p=0.05 level."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6181667975020345\n",
      "0.22291744531216273\n"
     ]
    }
   ],
   "source": [
    "# An example to show the cross validation for linear regression model\n",
    "cv_splits = cross_validation_split(X_train, y_train, 10)\n",
    "errs = []\n",
    "for split in cv_splits:\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(split['train']['X'], split['train']['y'])\n",
    "    errs.append(mean_squared_error(split['test']['y'], linear_model.predict(split['test']['X'])))\n",
    "\n",
    "    \n",
    "print(np.mean(errs))\n",
    "print(np.std(errs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_subset(\n",
    "    model: LinearRegression,\n",
    "    X_train: np.array,\n",
    "    y_train: np.array,\n",
    "    k: int = 1\n",
    ") -> tuple[tuple[float], tuple[int]]:\n",
    "    \"\"\"\n",
    "    Performs cross-validation for all possible models with subset k of the parameters.\n",
    "    \n",
    "    Args:\n",
    "        model   (LinearRegression): a model which has methods fit(X, y) and predict(X, y)\n",
    "        trainX          (np.array): input data\n",
    "        trainY          (np.array): target data\n",
    "        k                    (int): number of parameters in subset.\n",
    "\n",
    "    Returns:\n",
    "        tuple of (mean, std err) for the model with the best mean error, and tuple of indices of the k parameters\n",
    "    \"\"\"\n",
    "    p = X_train.shape[1]\n",
    "    if k > p:\n",
    "        raise ValueError('subset length cannot exceed number of parameters')\n",
    "    cv_means = []\n",
    "    cv_stds = []\n",
    "\n",
    "    subsets = list(combinations(range(p), k))\n",
    "    \n",
    "    for subset in subsets:\n",
    "        X_tmp = X_train[:,subset]\n",
    "\n",
    "        # Perform 10-fold cross-validation and record the mean and std\n",
    "        cv_splits = cross_validation_split(X_tmp, y_train, 10)\n",
    "        errs = []\n",
    "        for split in cv_splits:\n",
    "            model.fit(split['train']['X'], split['train']['y'])\n",
    "            errs.append(mean_squared_error(split['test']['y'], model.predict(split['test']['X'])))\n",
    "        \n",
    "        cv_means.append(np.mean(errs))\n",
    "        cv_stds.append(np.std(errs))\n",
    "\n",
    "    best_idx = np.argmin(cv_means)\n",
    "    return (cv_means[best_idx], cv_stds[best_idx]), subsets[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.520559951149077, 0.31249463944550215), (0, 1, 2, 3, 4, 5, 6, 7))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "best_subset(model, X_train, y_train, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5364729818856777,\n",
       " 0.6986050397052668,\n",
       " 0.5362366091020104,\n",
       " 0.5833112764610081,\n",
       " 0.5400502612471442,\n",
       " 0.48245153304718835,\n",
       " 0.5387613987196513,\n",
       " 0.48096454627348456,\n",
       " 0.5223120285404719]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "cv_means = []\n",
    "cv_stds = []\n",
    "for i in range(1,9):\n",
    "    best = best_subset(model, X_train, y_train, i)\n",
    "    cv_means.append(best[0][0])\n",
    "    cv_stds.append(best[0][1])\n",
    "\n",
    "dummy_model = DummyRegression()\n",
    "cv_splits = cross_validation_split(X_train, y_train, 10)\n",
    "dummy_errs = []\n",
    "for split in cv_splits:\n",
    "    dummy_model.fit(split['train']['X'], split['train']['y'])\n",
    "    dummy_errs.append(mean_squared_error(split['test']['y'], dummy_model.predict(split['test']['X'])))\n",
    "cv_means.insert(0, np.mean(dummy_errs))\n",
    "cv_stds.insert(0, np.std(dummy_errs))\n",
    "\n",
    "cv_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_subset = plot_cv_results(cv_means, cv_stds, list(range(0,9)), 'Subset Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d8c4c00aaea375f51ce0b653b564afd785a1adeeea68437cfc9eb80186c48f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
